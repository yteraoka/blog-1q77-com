---
title: 'eksctl ã§ä½•ãŒã§ãã‚‹ã®ã‹'
date: Sat, 11 Jan 2020 15:02:03 +0000
draft: false
tags: ['AWS', 'EKS']
---

[eksctl](https://eksctl.io/) ãŒä½•ã‚’ã‚„ã£ã¦ãã‚Œã‚‹ã®ãŒã€ä½•ãŒã§ãã‚‹ã®ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚

eksctl create cluster
---------------------

ã„ããªã‚Š `eksctl create cluster` ã‚’å®Ÿè¡Œã™ã‚‹ã ã‘ã§ã‚¯ãƒ©ã‚¹ã‚¿ãŒä½œã‚Œã‚‹ã£ã½ã„ã®ã§ã²ã¨ã¾ãšè©¦ã—ã¦ã¿ã‚‹ã€‚

```
$ eksctl create cluster
[â„¹]  eksctl version 0.12.0
[â„¹]  using region ap-northeast-1
[â„¹]  setting availability zones to [ap-northeast-1c ap-northeast-1d ap-northeast-1b]
[â„¹]  subnets for ap-northeast-1c - public:192.168.0.0/19 private:192.168.96.0/19
[â„¹]  subnets for ap-northeast-1d - public:192.168.32.0/19 private:192.168.128.0/19
[â„¹]  subnets for ap-northeast-1b - public:192.168.64.0/19 private:192.168.160.0/19
[â„¹]  nodegroup "ng-bb178f10" will use "ami-07296175bc6b826a5" [AmazonLinux2/1.14]
[â„¹]  using Kubernetes version 1.14
[â„¹]  creating EKS cluster "beautiful-badger-1578666058" in "ap-northeast-1" region with un-managed nodes
[â„¹]  will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup
[â„¹]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=ap-northeast-1 --cluster=beautiful-badger-1578666058'
[â„¹]  CloudWatch logging will not be enabled for cluster "beautiful-badger-1578666058" in "ap-northeast-1"
[â„¹]  you can enable it with 'eksctl utils update-cluster-logging --region=ap-northeast-1 --cluster=beautiful-badger-1578666058'
[â„¹]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "beautiful-badger-1578666058" in "ap-northeast-1"
[â„¹]  2 sequential tasks: { create cluster control plane "beautiful-badger-1578666058", create nodegroup "ng-bb178f10" }
[â„¹]  building cluster stack "eksctl-beautiful-badger-1578666058-cluster"
[â„¹]  deploying stack "eksctl-beautiful-badger-1578666058-cluster"
```

VPC ã‹ã‚‰ä¸€å¼å…¨éƒ¨ä½œã‚‹ CloudFormation ã® stack (ã“ã“ã§ã¯ eksctl-beautiful-badger-1578666058-cluster ã¨ã„ã†åå‰) ãŒä½œæˆã•ã‚Œã¦ deploy ãŒé–‹å§‹ã•ã‚Œã¾ã—ãŸã€‚AWS Console ã§ CloudFormation ã® stack ã‚’ç¢ºèªã™ã‚Œã°çŠ¶æ³ãŒã‚ã‹ã‚Šã¾ã™ã€‚ã‚ã‚Šã‚ƒï¼Ÿã‚¨ãƒ©ãƒ¼ãŒ...

```
[âœ–]  unexpected status "ROLLBACK_IN_PROGRESS" while waiting for CloudFormation stack "eksctl-beautiful-badger-1578666058-nodegroup-ng-bb178f10"
[â„¹]  fetching stack events in attempt to troubleshoot the root cause of the failure
[!]  AWS::EC2::SecurityGroupEgress/EgressInterClusterAPI: DELETE_IN_PROGRESS
[!]  AWS::EC2::SecurityGroupIngress/IngressInterClusterAPI: DELETE_IN_PROGRESS
[!]  AWS::EC2::SecurityGroupIngress/IngressInterClusterCP: DELETE_IN_PROGRESS
[!]  AWS::EC2::SecurityGroupEgress/EgressInterCluster: DELETE_IN_PROGRESS
[!]  AWS::AutoScaling::AutoScalingGroup/NodeGroup: DELETE_IN_PROGRESS
[!]  AWS::EC2::SecurityGroupIngress/IngressInterCluster: DELETE_IN_PROGRESS
[âœ–]  AWS::AutoScaling::AutoScalingGroup/NodeGroup: CREATE_FAILED â€“Â "AWS was not able to validate the provided access credentials (Service: AmazonAutoScaling; Status Code: 400; Error Code: ValidationError; Request ID: a31c5a54-33b6-11ea-9896-5308bff4139a)"
[â„¹]  1 error(s) occurred and cluster hasn't been created properly, you may wish to check CloudFormation console
[â„¹]  to cleanup resources, run 'eksctl delete cluster --region=ap-northeast-1 --name=beautiful-badger-1578666058'
[âœ–]  waiting for CloudFormation stack "eksctl-beautiful-badger-1578666058-nodegroup-ng-bb178f10": ResourceNotReady: failed waiting for successful resource state
Error: failed to create cluster "beautiful-badger-1578666058"
```

NodeGroup ã®ä½œæˆã§ã“ã‘ãŸã‚‰ã—ã„ã“ã¨ã¯åˆ†ã‹ã£ãŸãŒ... ğŸ˜£

```
AWS was not able to validate the provided access credentials (Service: AmazonAutoScaling; Status Code: 400; Error Code: ValidationError; Request ID: a31c5a54-33b6-11ea-9896-5308bff4139a)
```

å†ãƒãƒ£ãƒ¬ãƒ³ã‚¸ã—ãŸã‚‰ä»Šåº¦ã¯åˆ¥ã®ã¨ã“ã‚ã§ã‚³ã‚±ãŸ...

```
[âœ–]  AWS::EC2::Subnet/SubnetPublicAPNORTHEAST1A: CREATE_FAILED â€“Â "Value (ap-northeast-1a) for parameter availabilityZone is invalid. Subnets can currently only be created in the following availability zones: ap-northeast-1d, ap-northeast-1c, ap-northeast-1b. (Service: AmazonEC2; Status Code: 400; Error Code: InvalidParameterValue; Request ID: 28f3bfed-2939-4efd-ad9c-7f6152d6b041)"
[âœ–]  AWS::EC2::Subnet/SubnetPrivateAPNORTHEAST1A: CREATE_FAILED â€“Â "Value (ap-northeast-1a) for parameter availabilityZone is invalid. Subnets can currently only be created in the following availability zones: ap-northeast-1b, ap-northeast-1c, ap-northeast-1d. (Service: AmazonEC2; Status Code: 400; Error Code: InvalidParameterValue; Request ID: 0e402395-2b61-4b7f-ac5b-6e9f01625f0c)"
```

ã“ã®å¾Œã€æ•°å›è©¦ã—ãŸãŒã€å…¨éƒ¨ã“ã® AZ ã®å•é¡Œã§ã‚³ã‚±ãŸ...

ãã‚Œã§ã‚‚ã‚ã¨1å›ã€ã‚ã¨1å›ã¨æ€ã£ã¦è©¦ã—ã¦ãŸã‚‰æˆåŠŸã—ãŸã€‚(eksctl create cluster --zones=ap-northeast-1b,ap-northeast-1c,ap-northeast-1d ã¨ --zones ã‚’æŒ‡å®šã™ã‚Œã°è‰¯ã„ã®ã‹ãª) ã—ã‹ã—ã€AZ ã®å•é¡Œã¯ã‚ã‹ã‚‹ã‚“ã ã‘ã©ã€åˆå›ã®ã‚¨ãƒ©ãƒ¼ã¯å¿…ãšå†ç™ºã™ã‚‹ã®ã‹ã¨æ€ã£ã¦ãŸã®ã§æ„å¤–

```
$ eksctl create cluster                                                           
[â„¹]  eksctl version 0.12.0
[â„¹]  using region ap-northeast-1
[â„¹]  setting availability zones to [ap-northeast-1c ap-northeast-1d ap-northeast-1b]
[â„¹]  subnets for ap-northeast-1c - public:192.168.0.0/19 private:192.168.96.0/19
[â„¹]  subnets for ap-northeast-1d - public:192.168.32.0/19 private:192.168.128.0/19
[â„¹]  subnets for ap-northeast-1b - public:192.168.64.0/19 private:192.168.160.0/19
[â„¹]  nodegroup "ng-c384e850" will use "ami-07296175bc6b826a5" [AmazonLinux2/1.14]
[â„¹]  using Kubernetes version 1.14
[â„¹]  creating EKS cluster "wonderful-painting-1578669435" in "ap-northeast-1" region with un-managed nodes
[â„¹]  will create 2 separate CloudFormation stacks for cluster itself and the initial nodegroup
[â„¹]  if you encounter any issues, check CloudFormation console or try 'eksctl utils describe-stacks --region=ap-northeast-1 --cluster=wonderful-painting-1578669435'
[â„¹]  CloudWatch logging will not be enabled for cluster "wonderful-painting-1578669435" in "ap-northeast-1"
[â„¹]  you can enable it with 'eksctl utils update-cluster-logging --region=ap-northeast-1 --cluster=wonderful-painting-1578669435'
[â„¹]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "wonderful-painting-1578669435" in "ap-northeast-1"
[â„¹]  2 sequential tasks: { create cluster control plane "wonderful-painting-1578669435", create nodegroup "ng-c384e850" }
[â„¹]  building cluster stack "eksctl-wonderful-painting-1578669435-cluster"
[â„¹]  deploying stack "eksctl-wonderful-painting-1578669435-cluster"
[â„¹]  building nodegroup stack "eksctl-wonderful-painting-1578669435-nodegroup-ng-c384e850"
[â„¹]  --nodes-min=2 was set automatically for nodegroup ng-c384e850
[â„¹]  --nodes-max=2 was set automatically for nodegroup ng-c384e850
[â„¹]  deploying stack "eksctl-wonderful-painting-1578669435-nodegroup-ng-c384e850"
[âœ”]  all EKS cluster resources for "wonderful-painting-1578669435" have been created
[âœ”]  saved kubeconfig as "/Users/teraoka/.kube/config"
[â„¹]  adding identity "arn:aws:iam::949160801735:role/eksctl-wonderful-painting-1578669-NodeInstanceRole-18QXALFB6Y0W2" to auth ConfigMap
[â„¹]  nodegroup "ng-c384e850" has 0 node(s)
[â„¹]  waiting for at least 2 node(s) to become ready in "ng-c384e850"
[â„¹]  nodegroup "ng-c384e850" has 2 node(s)
[â„¹]  node "ip-192-168-12-245.ap-northeast-1.compute.internal" is ready
[â„¹]  node "ip-192-168-94-158.ap-northeast-1.compute.internal" is ready
[â„¹]  kubectl command should work with "/Users/teraoka/.kube/config", try 'kubectl get nodes'
[âœ”]  EKS cluster "wonderful-painting-1578669435" in "ap-northeast-1" region is ready
```

`~/.kube/config` ã«ä¿å­˜ã—ãŸã‚ˆã£ã¦å‡ºã¦ã‚‹ã‹ã‚‰ kubectl ã‚³ãƒãƒ³ãƒ‰ã‚’è©¦ã—ã¦ã¿ã‚‹ã€‚

```
$ kubectl get nodes
NAME                                                STATUS   ROLES    AGE     VERSION
ip-192-168-12-245.ap-northeast-1.compute.internal   Ready    3m25s   v1.14.8-eks-b8860f
ip-192-168-94-158.ap-northeast-1.compute.internal   Ready    3m24s   v1.14.8-eks-b8860f 
```

```
$ kubectl get svc --all-namespaces
NAMESPACE     NAME         TYPE        CLUSTER-IP    EXTERNAL-IP   PORT(S)         AGE
default       kubernetes   ClusterIP   10.100.0.1    443/TCP         16m
kube-system   kube-dns     ClusterIP   10.100.0.10   53/UDP,53/TCP   16m 
```

```
$ kubectl get ns 
NAME              STATUS   AGE
default           Active   17m
kube-node-lease   Active   17m
kube-public       Active   17m
kube-system       Active   17m
```

```
$ kubectl get pods --all-namespaces
NAMESPACE     NAME                       READY   STATUS    RESTARTS   AGE
kube-system   aws-node-b74p7             1/1     Running   0          11m
kube-system   aws-node-xx89x             1/1     Running   0          11m
kube-system   coredns-58986cd576-nc45g   1/1     Running   0          17m
kube-system   coredns-58986cd576-wcxcj   1/1     Running   0          17m
kube-system   kube-proxy-cfqcd           1/1     Running   0          11m
kube-system   kube-proxy-kzlgz           1/1     Running   0          11m
```

å‹•ã„ã¦ã‚‹ ğŸ˜

ã•ã¦ã€ã©ã‚“ãªãƒªã‚½ãƒ¼ã‚¹ãŒä½œã‚‰ã‚Œã¦ã„ã‚‹ã®ã‹ã€‚

- VPC
  - VPC ã‹ã‚‰æ–°ã—ãä½œã‚‰ã‚Œã‚‹
- Subnet
  - Public ã¨ Private ã¨ã„ã†2ç¨®é¡ã® Subnet ãŒãã‚Œãã‚Œ3ã¤ã® Availability zone ã«ä½œæˆã•ã‚Œã‚‹
- Internet Gateway
  - æ–°ã—ã„ VPC ã‚’ä½œã£ã¦ Public subnet ã‚’ä½œæˆã™ã‚‹ã®ã§å½“ç„¶ Internet Gateway ã‚‚å¿…è¦ã«ãªã‚‹
- Role
  - ServiceRole (Controle Plane ç”¨)ã€NodeInstanceRole (EC2 Workder Node ç”¨)ã€FargatePodExecutionRole ã®3ã¤ãŒä½œæˆã•ã‚Œã‚‹ã€‚ServiceRole ã¯ EKS ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ã‚‹ AmazonEKSClusterPolicyã€AmazonEKSServicePolicy ã¨ eksctl ãŒä½œã‚‹ PutMetrics ç”¨ Policy ã¨ NLB ç®¡ç†ç”¨ã® Policy ãŒç´ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹ã€‚NodeInstanceRole ã¯ EKS ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã‚ã‚‹ AmazonEKSWorkerNodePolicyã€AmazonEC2ContainerRegistryReadOnlyã€AmazonEKS\_CNI\_Policy ã®3ã¤ãŒã€FargatePodExecutionRole ã«ã¯ AmazonEKSFargatePodExecutionRolePolicy ãŒç´ä»˜ã‘ã‚‰ã‚Œã¦ã„ã‚‹
- NAT Gateway
  - Private subnet ãŒã‚ã‚‹ã®ã§ NAT Gateway ã‚‚ä½œæˆã•ã‚Œã‚‹ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯1ã¤ã® Availability zone ã«ã—ã‹ä½œã‚‰ã‚Œãªã„ãŒã€--vpc-nat-mode ã§ HighlyAvailable, Single, Disable ã‹ã‚‰é¸æŠã—ã¦æŒ‡å®šã™ã‚‹ã“ã¨ãŒå¯èƒ½ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ Single
- SecurityGroup
  - ã‚¯ãƒ©ã‚¹ã‚¿å†…ã® node é–“ã§ã®é€šä¿¡ç”¨ã«ä½œæˆã•ã‚Œã‚‹
- ControlePlane
  - ã‚‚ã¡ã‚ã‚“ Kubernetes ã® Controle Plane ãŒä½œã‚‰ã‚Œã‚‹
- AutoScalingGroup
  - Worker node ç”¨ã® AutoScalingGroup ãŒä½œã‚‰ã‚Œã‚‹
- LaunchTemplate
  - Worker node ç”¨ã® AutoScalingGroup ã§ä½¿ã‚ã‚Œã‚‹ LaunchTemplate ã§ AMI Image ã‚„ InstanceTypeã€InstanceProflieã€Userdata ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹

Worker node ã¨ã—ã¦ EC2 ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãŒä½œæˆã•ã‚ŒãŸã‚‰ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã¿ãŸã„ã¯ãšã€‚ã§ã‚‚ `eksctl create cluster` ã« `--ssh-access` (ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã™ã‚‹ãªã‚‰ `--ssh-public-key` ã‚‚) ã‚’ã¤ã‘ã¦ãŠã‹ãªã„ã¨ Public Key ãŒè¨­å®šã•ã‚Œãªã„ãŸã‚ worker node ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ã«ã¯ [EC2 Instance Connect](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-connect-methods.html) ã§æ¥ç¶šã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚[aws-instance-connect-cli](https://github.com/aws/aws-ec2-instance-connect-cli) ã‚’ä½¿ãˆã° `mssh <instance-id>` ã ã‘ã§æ¥ç¶šã§ãã‚‹ã€‚ ã—ã‹ã— Instance Connect ã¯ Instance Metadata Service v1 (IDMSv1) ã—ã‹ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„ã‚‰ã—ã„ã€‚æ¥ç¶šå…ˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¯ Global IP address ã‚’æŒã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã€SSH (22/tcp) ãŒ SecurityGroup ã§è¨±å¯ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚Web Console ã‹ã‚‰ AWS ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ã‹ã‚‰ã®æ¥ç¶šã‚’è¨±å¯ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚ã¾ãŸã€æ¥ç¶šã™ã‚‹äººã¯ IAM Policy ã§ [ec2-instance-connect:SendSSHPublicKey](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-instance-connect-set-up.html#ec2-instance-connect-configure-IAM-role) æ¨©é™ã‚’æŒã£ã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚‹ã€‚å…¬é–‹éµã‚’é€ã‚Šã¤ã‘ã¦ä¸€æ™‚çš„ã«ãƒ­ã‚°ã‚¤ãƒ³ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ãã‚Œã‚‹ã‚“ã§ã™ã­ã€‚

ã¨ã“ã‚ã§ã€worker node ã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã¿ãŸã‚‰ Pod ã”ã¨ã«2ã¤ã®ã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã—ã¦ã„ã¾ã—ãŸã€‚è¤‡æ•°ã‚³ãƒ³ãƒ†ãƒŠãŒæŒ‡å®šã•ã‚ŒãŸ Pod ã˜ã‚ƒãªã„ã®ã«ãªã‚“ã§ã ã‚ï¼Ÿã£ã¦æ€ã£ãŸã‚‰ã©ã‚Œã‚‚ "/pause" ãŒå®Ÿè¡Œã•ã‚Œã¦ã‚‹ã‚‚ã®ã¨ã€åå‰ã«åˆã£ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ã‚³ãƒ³ãƒ†ãƒŠã®2ã¤ã§ã—ãŸã€‚

```
CONTAINER ID        IMAGE                                                                   COMMAND                  CREATED             STATUS              PORTS               NAMES
df061216904c        602401143452.dkr.ecr.ap-northeast-1.amazonaws.com/eks/coredns           "/coredns -conf /etcâ€¦"   2 hours ago         Up 2 hours                              k8s_coredns_coredns-58986cd576-6kl57_kube-system_00aec73c-3449-11ea-a7e3-069c17bfdc00_0
379bc8e2844a        602401143452.dkr.ecr.ap-northeast-1.amazonaws.com/eks/pause-amd64:3.1   "/pause"                 2 hours ago         Up 2 hours                              k8s_POD_coredns-58986cd576-6kl57_kube-system_00aec73c-3449-11ea-a7e3-069c17bfdc00_0
09ee64a82565        602401143452.dkr.ecr.ap-northeast-1.amazonaws.com/amazon-k8s-cni        "/bin/sh -c /app/insâ€¦"   2 hours ago         Up 2 hours                              k8s_aws-node_aws-node-7l99l_kube-system_6f2001d2-344e-11ea-a7e3-069c17bfdc00_0
79eef819a1f4        602401143452.dkr.ecr.ap-northeast-1.amazonaws.com/eks/kube-proxy        "kube-proxy --v=2 --â€¦"   2 hours ago         Up 2 hours                              k8s_kube-proxy_kube-proxy-d599c_kube-system_6f202763-344e-11ea-a7e3-069c17bfdc00_0
40ae949a2e0c        602401143452.dkr.ecr.ap-northeast-1.amazonaws.com/eks/pause-amd64:3.1   "/pause"                 2 hours ago         Up 2 hours                              k8s_POD_aws-node-7l99l_kube-system_6f2001d2-344e-11ea-a7e3-069c17bfdc00_0
eeed9d5bf85f        602401143452.dkr.ecr.ap-northeast-1.amazonaws.com/eks/pause-amd64:3.1   "/pause"                 2 hours ago         Up 2 hours                              k8s_POD_kube-proxy-d599c_kube-system_6f202763-344e-11ea-a7e3-069c17bfdc00_0
```

[The Almighty Pause Container](https://www.ianlewis.org/en/almighty-pause-container) ã£ã¦ã®ã‚’è¦‹ã¤ã‘ãŸã€‚ã“ã‚ŒãŒ Pod ã¨ã„ã†è¤‡æ•°ã‚³ãƒ³ãƒ†ãƒŠã‚’ã¾ã¨ã‚ã‚‹ã‚­ãƒ¢ã ã£ãŸã‚“ã§ã™ã­ã€‚

Worker node ã¯èµ·å‹•æ™‚ã« Kubernetes ã®ã‚¯ãƒ©ã‚¹ã‚¿ã«å‚åŠ ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŒã€ã“ã‚Œã¯ AutoScalingGroup ã® LaunchTemplate ã« userdata è¨­å®šãŒã‚ã‚Šã¾ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆãŒ gzip ã•ã‚Œã¦ base64 ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã—ãŸã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã™ã‚‹ã¨æ¬¡ã®å†…å®¹ã§ã—ãŸã€‚

userdata

```yaml
#cloud-config
packages: null
runcmd:
- /var/lib/cloud/scripts/per-instance/bootstrap.al2.sh
write_files:
- content: |
    # eksctl-specific systemd drop-in unit for kubelet, for Amazon Linux 2 (AL2)

    [Service]
    # Local metadata parameters: REGION, AWS_DEFAULT_REGION
    EnvironmentFile=/etc/eksctl/metadata.env
    # Global and static parameters: CLUSTER_DNS, NODE_LABELS, NODE_TAINTS
    EnvironmentFile=/etc/eksctl/kubelet.env
    # Local non-static parameters: NODE_IP, INSTANCE_ID
    EnvironmentFile=/etc/eksctl/kubelet.local.env

    ExecStart=
    ExecStart=/usr/bin/kubelet \
      --node-ip=${NODE_IP} \
      --node-labels=${NODE_LABELS},alpha.eksctl.io/instance-id=${INSTANCE_ID} \
      --max-pods=${MAX_PODS} \
      --register-node=true --register-with-taints=${NODE_TAINTS} \
      --allow-privileged=true \
      --cloud-provider=aws \
      --container-runtime=docker \
      --network-plugin=cni \
      --cni-bin-dir=/opt/cni/bin \
      --cni-conf-dir=/etc/cni/net.d \
      --pod-infra-container-image=${AWS_EKS_ECR_ACCOUNT}.dkr.ecr.${AWS_DEFAULT_REGION}.amazonaws.com/eks/pause-amd64:3.1 \
      --kubeconfig=/etc/eksctl/kubeconfig.yaml \
      --config=/etc/eksctl/kubelet.yaml
  owner: root:root
  path: /etc/systemd/system/kubelet.service.d/10-eksclt.al2.conf
  permissions: "0644"
- content: |-
    NODE_LABELS=alpha.eksctl.io/cluster-name=hilarious-hideout-1578729265,alpha.eksctl.io/nodegroup-name=ng-b50c30b5
    NODE_TAINTS=
  owner: root:root
  path: /etc/eksctl/kubelet.env
  permissions: "0644"
- content: |
    address: 0.0.0.0
    apiVersion: kubelet.config.k8s.io/v1beta1
    authentication:
      anonymous:
        enabled: false
      webhook:
        cacheTTL: 2m0s
        enabled: true
      x509:
        clientCAFile: /etc/eksctl/ca.crt
    authorization:
      mode: Webhook
      webhook:
        cacheAuthorizedTTL: 5m0s
        cacheUnauthorizedTTL: 30s
    cgroupDriver: cgroupfs
    clusterDNS:
    - 10.100.0.10
    clusterDomain: cluster.local
    featureGates:
      RotateKubeletServerCertificate: true
    kind: KubeletConfiguration
    serverTLSBootstrap: true
  owner: root:root
  path: /etc/eksctl/kubelet.yaml
  permissions: "0644"
- content: |
    -----BEGIN CERTIFICATE-----
    (çœç•¥)
    -----END CERTIFICATE-----
  owner: root:root
  path: /etc/eksctl/ca.crt
  permissions: "0644"
- content: |
    apiVersion: v1
    clusters:
    - cluster:
        certificate-authority: /etc/eksctl/ca.crt
        server: https://7950C8F5B4E86FAF920EB443279E8896.sk1.ap-northeast-1.eks.amazonaws.com
      name: hilarious-hideout-1578729265.ap-northeast-1.eksctl.io
    contexts:
    - context:
        cluster: hilarious-hideout-1578729265.ap-northeast-1.eksctl.io
        user: kubelet@hilarious-hideout-1578729265.ap-northeast-1.eksctl.io
      name: kubelet@hilarious-hideout-1578729265.ap-northeast-1.eksctl.io
    current-context: kubelet@hilarious-hideout-1578729265.ap-northeast-1.eksctl.io
    kind: Config
    preferences: {}
    users:
    - name: kubelet@hilarious-hideout-1578729265.ap-northeast-1.eksctl.io
      user:
        exec:
          apiVersion: client.authentication.k8s.io/v1alpha1
          args:
          - token
          - -i
          - hilarious-hideout-1578729265
          command: aws-iam-authenticator
          env: null
  owner: root:root
  path: /etc/eksctl/kubeconfig.yaml
  permissions: "0644"
- content: |
    m5.24xlarge 737
    g4dn.4xlarge 29
    i3.xlarge 58
    ... (çœç•¥) ...
    t2.nano 4
    c3.xlarge 58
    c5.large 29
  owner: root:root
  path: /etc/eksctl/max_pods.map
  permissions: "0644"
- content: |-
    AWS_DEFAULT_REGION=ap-northeast-1
    AWS_EKS_CLUSTER_NAME=hilarious-hideout-1578729265
    AWS_EKS_ENDPOINT=https://7950C8F5B4E86FAF920EB443279E8896.sk1.ap-northeast-1.eks.amazonaws.com
    AWS_EKS_ECR_ACCOUNT=602401143452
  owner: root:root
  path: /etc/eksctl/metadata.env
  permissions: "0644"
- content: |
    #!/bin/bash

    set -o errexit
    set -o pipefail
    set -o nounset

    function get_max_pods() {
      while read instance_type pods; do
        if  [[ "${instance_type}" == "${1}" ]] && [[ "${pods}" =~ ^[0-9]+$ ]] ; then
          echo ${pods}
          return
        fi
      done < /etc/eksctl/max_pods.map
    }

    NODE_IP="$(curl --silent http://169.254.169.254/latest/meta-data/local-ipv4)"
    INSTANCE_ID="$(curl --silent http://169.254.169.254/latest/meta-data/instance-id)"
    INSTANCE_TYPE="$(curl --silent http://169.254.169.254/latest/meta-data/instance-type)"

    source /etc/eksctl/kubelet.env # this can override MAX_PODS

    cat > /etc/eksctl/kubelet.local.env <<EOF
    NODE_IP=${NODE_IP}
    INSTANCE_ID=${INSTANCE_ID}
    INSTANCE_TYPE=${INSTANCE_TYPE}
    MAX_PODS=${MAX_PODS:-$(get_max_pods "${INSTANCE_TYPE}")}
    EOF

    systemctl daemon-reload
    systemctl enable kubelet
    systemctl start kubelet
  owner: root:root
  path: /var/lib/cloud/scripts/per-instance/bootstrap.al2.sh
  permissions: "0755"
```

ã§ã‚‚ä»Šã¯ [Managed Node Group](https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html) ã£ã¦ã®ãŒã‚ã‚‹ã®ã§ã“ã‚Œã‚’ä½¿ã†ã®ãŒè‰¯ã„ã®ã‹ãªã€‚eksctl create cluster ã« --managed ã‚’ã¤ã‘ã‚‹ã ã‘ã§è‰¯ã•ãã†ã€‚ã¾ãŸã€--fargate ã‚’ã¤ã‘ã‚Œã° Fargate ã§å®Ÿè¡Œã™ã‚‹è¨­å®šãŒå…¥ã‚‹ã£ã½ã„ã€‚ã“ã®è¾ºã‚Šã‚’ç¢ºèªã—ã¦ terraform ã§ EKS ç’°å¢ƒã‚’æ§‹ç¯‰ã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã¿ã‚‹ã“ã¨ã«ã™ã‚‹ã€‚
